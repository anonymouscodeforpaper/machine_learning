{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "THREADS = 16\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv('train.csv')\n",
    "testset = pd.read_csv('test.csv')\n",
    "def traite_train_test(df):\n",
    "    df['actors'] = df['actors'].apply(lambda x: json.loads(x))\n",
    "    df['director'] = df['director'].apply(lambda x: json.loads(x))\n",
    "    df['genre'] = df['genre'].apply(lambda x: json.loads(x))\n",
    "    return df\n",
    "hehe_test = traite_train_test(trainset)\n",
    "df_empty = traite_train_test(testset)\n",
    "df_empty['user_id'] = df_empty['user_id'].astype('int')\n",
    "df_empty['user_rating'] = df_empty['user_rating'].astype('float')\n",
    "df_empty['movie'] = df_empty['movie'].astype('int')\n",
    "hehe_test.index = range(len(hehe_test))\n",
    "df_empty.index = range(len(df_empty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-55be2c786f61>:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_empty.append(hehe_test)\n"
     ]
    }
   ],
   "source": [
    "df_all = df_empty.append(hehe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 1238)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(hehe_test['user_id']),max(hehe_test['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_fm(BIAS, bias, feature_embeddings):\n",
    "    inter1 = torch.square(feature_embeddings.sum(0))\n",
    "    inter2 = torch.square(feature_embeddings).sum(0)\n",
    "    out = 0.5 * (inter1 - inter2)\n",
    "    out = out.sum()\n",
    "    out = BIAS + bias + out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jiumin(first, user_item_id, actors_id, directors_id, genres_id, aspects, user_item_aspect, bias, BIAS):\n",
    "    val_base = actors_id[first]\n",
    "    actor_base = torch.LongTensor(val_base)\n",
    "    bias_actors = bias(actor_base).squeeze(1).sum()\n",
    "    actors_base = aspects(actor_base)\n",
    "\n",
    "    val_base = directors_id[first]\n",
    "    director_base = torch.LongTensor(val_base)\n",
    "    bias_directors = bias(director_base).squeeze(1).sum()\n",
    "    director_base = aspects(director_base)\n",
    "\n",
    "    val_base = genres_id[first]\n",
    "    genre_base = torch.LongTensor(val_base)\n",
    "    bias_genres = bias(genre_base).squeeze(1).sum()\n",
    "    genre_base = aspects(genre_base)\n",
    "\n",
    "    val_base = user_item_id[first]\n",
    "    user_item_base = torch.LongTensor(val_base)\n",
    "    bias_user_items = bias(user_item_base).squeeze(1).sum()  # 1* n * 1\n",
    "    user_item_base = user_item_aspect(user_item_base)  # 1 * 2 * dim\n",
    "\n",
    "    bias_all = bias_actors + bias_directors + bias_genres + bias_user_items\n",
    "\n",
    "    batch_embedding = torch.cat(\n",
    "        (actors_base, director_base, genre_base, user_item_base), 0)\n",
    "\n",
    "    pre_rating = basic_fm(BIAS, bias_all, batch_embedding)\n",
    "    return pre_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self, n_user_item, n_features, n_factors):\n",
    "        super(FM, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_factors = n_factors\n",
    "        self.features_factors = torch.nn.Embedding(n_features, n_factors)\n",
    "        self.user_item_factors = torch.nn.Embedding(n_user_item, n_factors)\n",
    "        self.bias = torch.nn.Embedding(n_features, 1)\n",
    "        self.BIAS = torch.nn.Embedding(1, 1)\n",
    "\n",
    "    def forward(self, user_item_id, actors_id, directors_id, genres_id):\n",
    "\n",
    "        aspects = self.features_factors\n",
    "        user_item_aspect = self.user_item_factors\n",
    "        bias = self.bias\n",
    "        bias = self.bias\n",
    "        BIAS = self.BIAS.weight.squeeze(1)\n",
    "\n",
    "        first = actors_id.index[0]\n",
    "        pre_rating = jiumin(\n",
    "            first, user_item_id, actors_id, directors_id, genres_id, aspects, user_item_aspect, bias, BIAS)\n",
    "        for i in actors_id.index[1:]:\n",
    "            actors_f = jiumin(i, user_item_id, actors_id,\n",
    "                              directors_id, genres_id, aspects, user_item_aspect, bias, BIAS)\n",
    "            pre_rating = torch.cat((pre_rating, actors_f))\n",
    "        return pre_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hehe_test.copy()\n",
    "i = 0\n",
    "batch_size = 2\n",
    "num_example = 86572\n",
    "indices = list(range(num_example))\n",
    "\n",
    "model_test = FM(2182, 4328, 32)\n",
    "aspects = model_test.features_factors\n",
    "user_item_aspect = model_test.user_item_factors\n",
    "bias = model_test.bias\n",
    "bias = model_test.bias\n",
    "BIAS = model_test.BIAS.weight.squeeze(1)\n",
    "\n",
    "\n",
    "indexs = indices[i:min(i+batch_size, num_example)]\n",
    "user_item_id = data.iloc[:, 0:2].loc[indexs].values\n",
    "actors_id = data.iloc[:, 2].loc[indexs]\n",
    "actors_id.index = range(len(actors_id))\n",
    "directors_id = data.iloc[:, 3].loc[indexs]\n",
    "directors_id.index = range(len(directors_id))\n",
    "genres_id = data.iloc[:, 4].loc[indexs]\n",
    "genres_id.index = range(len(genres_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = actors_id.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3026134800550207"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.3788-0.2908)/0.2908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bias_actors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbias_actors\u001b[49m,bias_directors,bias_genres,bias_user_items,bias_all\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bias_actors' is not defined"
     ]
    }
   ],
   "source": [
    "bias_actors,bias_directors,bias_genres,bias_user_items,bias_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 32]),\n",
       " torch.Size([1, 32]),\n",
       " torch.Size([3, 32]),\n",
       " torch.Size([2, 32]),\n",
       " torch.Size([11, 32]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actors_base.shape,director_base.shape,genre_base.shape,user_item_base.shape,batch_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_base = actors_id[first]\n",
    "actor_base = torch.LongTensor(val_base)\n",
    "bias_actors = bias(actor_base).sum()\n",
    "actors_base = aspects(actor_base)\n",
    "\n",
    "val_base = directors_id[first]\n",
    "director_base = torch.LongTensor(val_base)\n",
    "bias_directors = bias(director_base).sum()\n",
    "director_base = aspects(director_base)\n",
    "\n",
    "val_base = genres_id[first]\n",
    "genre_base = torch.LongTensor(val_base)\n",
    "bias_genres = bias(genre_base).sum()\n",
    "genre_base = aspects(genre_base)\n",
    "\n",
    "val_base = user_item_id[first]\n",
    "user_item_base = torch.LongTensor(val_base)\n",
    "bias_user_items = bias(user_item_base).squeeze(1).sum()  # 1* n * 1\n",
    "user_item_base = user_item_aspect(user_item_base)  # 1 * 2 * dim\n",
    "\n",
    "bias_all = bias_actors + bias_directors + bias_genres + bias_user_items\n",
    "\n",
    "batch_embedding = torch.cat(\n",
    "    (user_item_base,actors_base, director_base, genre_base), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.2905, grad_fn=<SumBackward0>),\n",
       " tensor(-0.4905, grad_fn=<SumBackward0>),\n",
       " tensor(2.0874, grad_fn=<SumBackward0>),\n",
       " tensor(-0.1492, grad_fn=<SumBackward0>),\n",
       " tensor(4.7382, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_actors,bias_directors,bias_genres,bias_user_items,bias_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 32]),\n",
       " torch.Size([1, 32]),\n",
       " torch.Size([3, 32]),\n",
       " torch.Size([2, 32]),\n",
       " torch.Size([11, 32]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_base.shape,director_base.shape,genre_base.shape,user_item_base.shape,batch_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_embedding.sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter1 = torch.square(batch_embedding.sum(0))\n",
    "inter2 = torch.square(batch_embedding).sum(0)\n",
    "inter1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter1 = torch.square(batch_embedding.sum(0))\n",
    "inter2 = torch.square(batch_embedding).sum(0)\n",
    "out = 0.5 * (inter1 - inter2)\n",
    "out = out.sum()\n",
    "out = BIAS + bias_all + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(data, model):\n",
    "    user_item_index = data.iloc[:, 0:2].values\n",
    "    actors_id = data.iloc[:, 2] \n",
    "    directors_id = data.iloc[:, 3]\n",
    "    genres_id = data.iloc[:, 4]\n",
    "    rating = torch.FloatTensor(\n",
    "        data.iloc[:, 5].values).to(DEVICE)\n",
    "    prediction = model(user_item_index, actors_id, directors_id, genres_id)\n",
    "    rmse = loss_func(prediction, rating)\n",
    "    mae = torch.nn.L1Loss()(prediction, rating)\n",
    "    \n",
    "    return rmse ** 0.5,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hehe_test['movie'] = hehe_test['movie'] + 943\n",
    "# df_empty['movie'] = df_empty['movie'] + 943\n",
    "#df_all['movie'] = df_all['movie'] + 943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1238"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_all['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, dim, reg, batch_size, num_epochs, data, test):\n",
    "    model = FM(2182, 4328, dim).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr,weight_decay=reg)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=10, threshold_mode='abs',threshold = 0.005)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        t1 = time.time()\n",
    "        num_example = len(data)\n",
    "        indices = list(range(num_example))\n",
    "        for i in range(0, num_example, batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            indexs = indices[i:min(i+batch_size, num_example)]\n",
    "            users_index = data.iloc[:, 0:2].loc[indexs].values\n",
    "            actors_id = data.iloc[:, 2].loc[indexs]\n",
    "            actors_id.index = range(len(actors_id))\n",
    "            directors_id = data.iloc[:, 3].loc[indexs]\n",
    "            directors_id.index = range(len(directors_id))\n",
    "            genres_id = data.iloc[:, 4].loc[indexs]\n",
    "            genres_id.index = range(len(genres_id))\n",
    "            rating = torch.FloatTensor(\n",
    "                data.iloc[:, 5].loc[indexs].values).to(DEVICE)\n",
    "            prediction = model(\n",
    "                users_index, actors_id, directors_id, genres_id)\n",
    "\n",
    "            err = loss_func(prediction, rating) \n",
    "            err.backward()\n",
    "            optimizer.step()\n",
    "        t2 = time.time()\n",
    "        rmse, mae = RMSE(test, model)\n",
    "        scheduler.step(rmse)\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(\"Epoch: \", epoch, \" Loss: \", err, \" RMSE in test set:\",\n",
    "              rmse, \"MAE in test set: \", mae)\n",
    "            print(\"Time consumed is:\", t2-t1)\n",
    "    return rmse, mae, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(lrs, dims, regs, batch_sizes, num_epochs, data, test):\n",
    "    res = []\n",
    "    models = []\n",
    "    qnm = []\n",
    "    for lr in lrs:\n",
    "        for dim in dims:\n",
    "            for reg in regs:\n",
    "                for batch_size in batch_sizes:\n",
    "                    rmse, mae, model = train(\n",
    "                        lr, dim, reg, batch_size, num_epochs, data, test)\n",
    "                    res.append(rmse)\n",
    "                    res.append(mae)\n",
    "\n",
    "                    models.append(model)\n",
    "                    state = { 'model': model.state_dict()}   \n",
    "                    torch.save(state, 'fm/fm_' + str(lr) + '_' + str(dim) + '_' + str(reg) + '_' + str(batch_size) + '.pkl')\n",
    "                    \n",
    "    return res, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 1e-2\n",
    "# dim = 32\n",
    "# reg = 4e-5\n",
    "# batch_size = 128 \n",
    "# num_epochs = 100\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn import LeakyReLU\n",
    "# model_fm = train(lr, dim, reg, batch_size, num_epochs, hehe_test,df_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  49  Loss:  tensor(0.6841, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(1.3895, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.1058, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 57.71477675437927\n",
      "Epoch:  99  Loss:  tensor(0.0473, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.7127, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.5701, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 56.713467836380005\n",
      "Epoch:  149  Loss:  tensor(0.0356, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.6522, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.5130, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 59.34599781036377\n",
      "Epoch:  49  Loss:  tensor(0.2352, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(1.0757, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.8539, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 58.28889465332031\n",
      "Epoch:  99  Loss:  tensor(0.0833, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.5882, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4568, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 57.13801145553589\n",
      "Epoch:  149  Loss:  tensor(0.0020, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.4981, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.3688, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 54.6874577999115\n",
      "Epoch:  49  Loss:  tensor(0.3647, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(1.2309, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.9740, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 55.70725989341736\n",
      "Epoch:  99  Loss:  tensor(0.0469, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.7051, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.5596, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 57.92664861679077\n",
      "Epoch:  149  Loss:  tensor(0.0303, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.6411, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4951, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 56.53947734832764\n",
      "Epoch:  49  Loss:  tensor(1.0224, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(1.4376, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.1989, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 50.94338369369507\n",
      "Epoch:  99  Loss:  tensor(0.1625, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.6999, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.5590, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 53.332741498947144\n",
      "Epoch:  149  Loss:  tensor(0.0014, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.4963, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.3680, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 53.071139097213745\n",
      "Epoch:  49  Loss:  tensor(2.3824, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(2.1451, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.6002, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 58.19408893585205\n",
      "Epoch:  99  Loss:  tensor(0.0426, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.7143, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.5289, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 58.21827936172485\n",
      "Epoch:  149  Loss:  tensor(0.0313, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.6215, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4620, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 58.994983434677124\n",
      "Epoch:  49  Loss:  tensor(2.5258, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(2.2472, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.8226, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 55.44786763191223\n",
      "Epoch:  99  Loss:  tensor(0.1252, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.5842, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4525, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 55.32598519325256\n",
      "Epoch:  149  Loss:  tensor(0.0275, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.4395, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.3247, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 55.902827978134155\n",
      "Epoch:  49  Loss:  tensor(0.6088, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(1.4027, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.0768, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 57.18372416496277\n",
      "Epoch:  99  Loss:  tensor(0.0671, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.7474, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.5709, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 59.563881397247314\n",
      "Epoch:  149  Loss:  tensor(0.0639, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.6329, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4820, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 60.46727514266968\n",
      "Epoch:  49  Loss:  tensor(6.9775, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(3.1563, grad_fn=<PowBackward0>) MAE in test set:  tensor(2.3356, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 56.88564085960388\n",
      "Epoch:  99  Loss:  tensor(0.1533, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.5772, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4484, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 56.54223108291626\n",
      "Epoch:  149  Loss:  tensor(0.0127, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.3936, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.2732, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 50.0473153591156\n",
      "Epoch:  49  Loss:  tensor(1.8130, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(2.7634, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.9799, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 75.3796899318695\n",
      "Epoch:  99  Loss:  tensor(0.1686, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(1.0176, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.7380, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 63.713504791259766\n",
      "Epoch:  149  Loss:  tensor(0.0335, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.6725, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4762, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 71.57125782966614\n",
      "Epoch:  49  Loss:  tensor(2.0239, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(1.6229, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.2574, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 67.48853039741516\n",
      "Epoch:  99  Loss:  tensor(0.0240, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.4424, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.3106, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 66.47950053215027\n",
      "Epoch:  149  Loss:  tensor(0.0011, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.3035, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.1974, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 62.486430406570435\n",
      "Epoch:  49  Loss:  tensor(11.0858, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(5.0280, grad_fn=<PowBackward0>) MAE in test set:  tensor(4.0944, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 67.4841878414154\n",
      "Epoch:  99  Loss:  tensor(0.1105, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.8766, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.6404, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 65.35173964500427\n",
      "Epoch:  149  Loss:  tensor(0.0321, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.5995, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4240, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 72.42145037651062\n",
      "Epoch:  49  Loss:  tensor(4.4741, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(2.3581, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.7331, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 60.74666714668274\n",
      "Epoch:  99  Loss:  tensor(0.0676, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.4931, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.3553, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 66.99084138870239\n",
      "Epoch:  149  Loss:  tensor(0.0224, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(0.3469, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.2448, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 70.10590744018555\n",
      "Epoch:  49  Loss:  tensor(318.2971, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(21.5020, grad_fn=<PowBackward0>) MAE in test set:  tensor(16.9258, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 50.18186330795288\n",
      "Epoch:  99  Loss:  tensor(4.2733, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(5.2675, grad_fn=<PowBackward0>) MAE in test set:  tensor(3.5894, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 50.49322056770325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  149  Loss:  tensor(4.8116, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(4.2690, grad_fn=<PowBackward0>) MAE in test set:  tensor(3.0072, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 49.80368185043335\n",
      "Epoch:  49  Loss:  tensor(1021.7432, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(33.6661, grad_fn=<PowBackward0>) MAE in test set:  tensor(25.5053, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 47.47133255004883\n",
      "Epoch:  99  Loss:  tensor(0.4313, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(2.2191, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.5319, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 49.11369967460632\n",
      "Epoch:  149  Loss:  tensor(0.6336, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(1.6353, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.1734, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 48.98140740394592\n",
      "Epoch:  49  Loss:  tensor(311.7751, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(20.2544, grad_fn=<PowBackward0>) MAE in test set:  tensor(15.9104, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 49.39533615112305\n",
      "Epoch:  99  Loss:  tensor(4.1454, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(4.9811, grad_fn=<PowBackward0>) MAE in test set:  tensor(3.3894, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 49.88928008079529\n",
      "Epoch:  149  Loss:  tensor(4.1211, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(3.9689, grad_fn=<PowBackward0>) MAE in test set:  tensor(2.8319, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 50.8067741394043\n",
      "Epoch:  49  Loss:  tensor(301.7653, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(18.4085, grad_fn=<PowBackward0>) MAE in test set:  tensor(12.8190, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 47.8954713344574\n",
      "Epoch:  99  Loss:  tensor(7.9300, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(4.8764, grad_fn=<PowBackward0>) MAE in test set:  tensor(3.3646, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 47.9515540599823\n",
      "Epoch:  149  Loss:  tensor(6.7627, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(3.9291, grad_fn=<PowBackward0>) MAE in test set:  tensor(2.8382, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 51.53443193435669\n",
      "Epoch:  49  Loss:  tensor(1056.0726, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(38.2728, grad_fn=<PowBackward0>) MAE in test set:  tensor(30.7630, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 52.723705530166626\n",
      "Epoch:  99  Loss:  tensor(0.8118, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(6.2532, grad_fn=<PowBackward0>) MAE in test set:  tensor(4.0584, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 54.163368463516235\n",
      "Epoch:  149  Loss:  tensor(3.3662, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(4.9794, grad_fn=<PowBackward0>) MAE in test set:  tensor(3.3993, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 53.56256055831909\n",
      "Epoch:  49  Loss:  tensor(2058.1223, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(51.1217, grad_fn=<PowBackward0>) MAE in test set:  tensor(38.8778, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 51.66683864593506\n",
      "Epoch:  99  Loss:  tensor(32.5524, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(7.5320, grad_fn=<PowBackward0>) MAE in test set:  tensor(5.3781, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 49.436230182647705\n",
      "Epoch:  149  Loss:  tensor(4.4743, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(4.2439, grad_fn=<PowBackward0>) MAE in test set:  tensor(2.9634, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 50.96694207191467\n",
      "Epoch:  49  Loss:  tensor(861.9385, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(41.5977, grad_fn=<PowBackward0>) MAE in test set:  tensor(32.5366, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 53.03698015213013\n",
      "Epoch:  99  Loss:  tensor(1.3863, grad_fn=<MseLossBackward0>)  RMSE in test set: tensor(6.9654, grad_fn=<PowBackward0>) MAE in test set:  tensor(4.5547, grad_fn=<L1LossBackward0>)\n",
      "Time consumed is: 54.25917458534241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[1;32m      7\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m res_reg, models_reg \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43mregs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhehe_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_empty\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36mgrid\u001b[0;34m(lrs, dims, regs, batch_sizes, num_epochs, data, test)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reg \u001b[38;5;129;01min\u001b[39;00m regs:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m batch_sizes:\n\u001b[0;32m----> 9\u001b[0m         rmse, mae, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(rmse)\n\u001b[1;32m     12\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(mae)\n",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(lr, dim, reg, batch_size, num_epochs, data, test)\u001b[0m\n\u001b[1;32m     23\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     24\u001b[0m         users_index, actors_id, directors_id, genres_id)\n\u001b[1;32m     26\u001b[0m     err \u001b[38;5;241m=\u001b[39m loss_func(prediction, rating) \n\u001b[0;32m---> 27\u001b[0m     \u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rate = 0.0\n",
    "lrs = [1e-2,5e-2]\n",
    "dims = [16,32,64]\n",
    "regs = [1e-6,1e-7]\n",
    "batch_sizes = [128,256]\n",
    "num_epochs = 150\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "res_reg, models_reg = grid(lrs,dims,regs,batch_sizes,num_epochs,hehe_test,df_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    " #conding=utf8  \n",
    "import os \n",
    "\n",
    "path = \"fm/\" \n",
    "def get_file_name(path):\n",
    "    for file in os.listdir(path):\n",
    "        lr = file.split('_')[1]\n",
    "        dim = file.split('_')[2]\n",
    "        reg = file.split('_')[3]\n",
    "        batch_size = file.split('_')[4][:3]\n",
    "        \n",
    "        model = FM(2182, 4328, int(file.split('_')[2])).to(DEVICE)\n",
    "        load_params = torch.load('fm/' + file)['model']\n",
    "        model_params = model.state_dict()\n",
    "        same_parsms = {k: v for k, v in load_params.items() if k in model_params.keys()}\n",
    "        model_params.update(same_parsms)\n",
    "\n",
    "        model.load_state_dict(model_params)\n",
    "        rmse, mae = RMSE(df_empty, model)\n",
    "        print(\"Learning rate: \",lr, \"dimension of vector: \", dim, \"Regularization rate: \", reg,\"Batch_size: \", batch_size)\n",
    "        print(\" RMSE in test set:\",\n",
    "              rmse, \"MAE in test set: \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.1 dimension of vector:  16 Regularization rate:  1e-06 Batch_size:  256\n",
      " RMSE in test set: tensor(13.6390, grad_fn=<PowBackward0>) MAE in test set:  tensor(9.8624, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.05 dimension of vector:  16 Regularization rate:  1e-07 Batch_size:  256\n",
      " RMSE in test set: tensor(3.9291, grad_fn=<PowBackward0>) MAE in test set:  tensor(2.8382, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.001 dimension of vector:  16 Regularization rate:  1e-06 Batch_size:  128\n",
      " RMSE in test set: tensor(1.3709, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.0858, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  16 Regularization rate:  1e-07 Batch_size:  128\n",
      " RMSE in test set: tensor(0.6411, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4951, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.001 dimension of vector:  16 Regularization rate:  1e-07 Batch_size:  128\n",
      " RMSE in test set: tensor(1.4313, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.1387, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.05 dimension of vector:  16 Regularization rate:  1e-06 Batch_size:  128\n",
      " RMSE in test set: tensor(4.2690, grad_fn=<PowBackward0>) MAE in test set:  tensor(3.0072, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  32 Regularization rate:  1e-06 Batch_size:  128\n",
      " RMSE in test set: tensor(0.6215, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4620, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.001 dimension of vector:  16 Regularization rate:  1e-06 Batch_size:  256\n",
      " RMSE in test set: tensor(1.4583, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.1197, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  32 Regularization rate:  1e-07 Batch_size:  128\n",
      " RMSE in test set: tensor(0.6329, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4820, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.05 dimension of vector:  32 Regularization rate:  1e-06 Batch_size:  256\n",
      " RMSE in test set: tensor(4.2439, grad_fn=<PowBackward0>) MAE in test set:  tensor(2.9634, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.05 dimension of vector:  16 Regularization rate:  1e-06 Batch_size:  256\n",
      " RMSE in test set: tensor(1.6353, grad_fn=<PowBackward0>) MAE in test set:  tensor(1.1734, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.05 dimension of vector:  32 Regularization rate:  1e-06 Batch_size:  128\n",
      " RMSE in test set: tensor(4.9794, grad_fn=<PowBackward0>) MAE in test set:  tensor(3.3993, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  32 Regularization rate:  1e-06 Batch_size:  256\n",
      " RMSE in test set: tensor(0.4395, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.3247, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  16 Regularization rate:  1e-07 Batch_size:  256\n",
      " RMSE in test set: tensor(0.4963, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.3680, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.1 dimension of vector:  16 Regularization rate:  1e-06 Batch_size:  128\n",
      " RMSE in test set: tensor(12.3144, grad_fn=<PowBackward0>) MAE in test set:  tensor(8.8950, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  16 Regularization rate:  1e-06 Batch_size:  128\n",
      " RMSE in test set: tensor(0.6522, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.5130, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  64 Regularization rate:  1e-07 Batch_size:  256\n",
      " RMSE in test set: tensor(0.3469, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.2448, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  32 Regularization rate:  1e-07 Batch_size:  256\n",
      " RMSE in test set: tensor(0.3936, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.2732, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  64 Regularization rate:  1e-06 Batch_size:  128\n",
      " RMSE in test set: tensor(0.6725, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4762, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.05 dimension of vector:  16 Regularization rate:  1e-07 Batch_size:  128\n",
      " RMSE in test set: tensor(3.9689, grad_fn=<PowBackward0>) MAE in test set:  tensor(2.8319, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  16 Regularization rate:  1e-06 Batch_size:  256\n",
      " RMSE in test set: tensor(0.4981, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.3688, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  64 Regularization rate:  1e-06 Batch_size:  256\n",
      " RMSE in test set: tensor(0.3035, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.1974, grad_fn=<L1LossBackward0>)\n",
      "Learning rate:  0.01 dimension of vector:  64 Regularization rate:  1e-07 Batch_size:  128\n",
      " RMSE in test set: tensor(0.5995, grad_fn=<PowBackward0>) MAE in test set:  tensor(0.4240, grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "get_file_name(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
